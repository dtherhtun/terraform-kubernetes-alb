locals {
  aws_alb_ingress_controller_docker_image = "docker.io/amazon/aws-alb-ingress-controller:v${var.aws_alb_ingress_controller_version}"
  aws_alb_ingress_controller_version      = var.aws_alb_ingress_controller_version
  aws_alb_ingress_class                   = "alb"
  aws_vpc_id                              = data.aws_vpc.selected.id
  aws_region_name                         = data.aws_region.current.name
  aws_iam_path_prefix                     = var.aws_iam_path_prefix == "" ? null : var.aws_iam_path_prefix
}

data "aws_vpc" "selected" {
  id = var.k8s_cluster_type == "eks" ? data.aws_eks_cluster.selected[0].vpc_config[0].vpc_id : var.aws_vpc_id
}

data "aws_region" "current" {
  name = var.aws_region_name
}

data "aws_caller_identity" "current" {}

# The EKS cluster (if any) that represents the installation target.
data "aws_eks_cluster" "selected" {
  count = var.k8s_cluster_type == "eks" ? 1 : 0
  name  = var.k8s_cluster_name
}

#data "aws_iam_policy_document" "ec2_assume_role" {
#  count = var.k8s_cluster_type == "vanilla" ? 1 : 0
#  statement {
#    actions = ["sts:AssumeRole"]
#
#    principals {
#      type        = "Service"
#      identifiers = ["ec2.amazonaws.com"]
#    }
#  }
#}
#
#data "aws_iam_policy_document" "eks_oidc_assume_role" {
#  count = var.k8s_cluster_type == "eks" ? 1 : 0
#  statement {
#    actions = ["sts:AssumeRoleWithWebIdentity"]
#    effect  = "Allow"
#    condition {
#      test     = "StringEquals"
#      variable = "${replace(data.aws_eks_cluster.selected[0].identity[0].oidc[0].issuer, "https://", "")}:sub"
#      values = [
#        "system:serviceaccount:${var.k8s_namespace}:aws-alb-ingress-controller"
#      ]
#    }
#    principals {
#      identifiers = [
#        "arn:aws:iam::${data.aws_caller_identity.current.account_id}:oidc-provider/${replace(data.aws_eks_cluster.selected[0].identity[0].oidc[0].issuer, "https://", "")}"
#      ]
#      type = "Federated"
#    }
#  }
#}
#
#resource "aws_iam_role" "this" {
#  name        = "${var.aws_resource_name_prefix}${var.k8s_cluster_name}-alb-ingress-controller"
#  description = "Permissions required by the Kubernetes AWS ALB Ingress controller to do it's job."
#  path        = local.aws_iam_path_prefix
#
#  tags = var.aws_tags
#
#  force_detach_policies = true
#
#  assume_role_policy = var.k8s_cluster_type == "vanilla" ? data.aws_iam_policy_document.ec2_assume_role[0].json : data.aws_iam_policy_document.eks_oidc_assume_role[0].json
#}
#
#data "aws_iam_policy_document" "alb_management" {
#  statement {
#    actions = [
#      "acm:DescribeCertificate",
#      "acm:ListCertificates",
#      "acm:GetCertificate",
#    ]
#
#    resources = ["*"]
#  }
#
#  statement {
#    actions = [
#      "ec2:AuthorizeSecurityGroupIngress",
#      "ec2:CreateSecurityGroup",
#      "ec2:CreateTags",
#      "ec2:DeleteTags",
#      "ec2:DeleteSecurityGroup",
#      "ec2:DescribeAccountAttributes",
#      "ec2:DescribeAddresses",
#      "ec2:DescribeInstances",
#      "ec2:DescribeInstanceStatus",
#      "ec2:DescribeInternetGateways",
#      "ec2:DescribeNetworkInterfaces",
#      "ec2:DescribeSecurityGroups",
#      "ec2:DescribeSubnets",
#      "ec2:DescribeTags",
#      "ec2:DescribeVpcs",
#      "ec2:ModifyInstanceAttribute",
#      "ec2:ModifyNetworkInterfaceAttribute",
#      "ec2:RevokeSecurityGroupIngress",
#    ]
#
#    resources = ["*"]
#  }
#
#  statement {
#    actions = [
#      "elasticloadbalancing:AddListenerCertificates",
#      "elasticloadbalancing:AddTags",
#      "elasticloadbalancing:CreateListener",
#      "elasticloadbalancing:CreateLoadBalancer",
#      "elasticloadbalancing:CreateRule",
#      "elasticloadbalancing:CreateTargetGroup",
#      "elasticloadbalancing:DeleteListener",
#      "elasticloadbalancing:DeleteLoadBalancer",
#      "elasticloadbalancing:DeleteRule",
#      "elasticloadbalancing:DeleteTargetGroup",
#      "elasticloadbalancing:DeregisterTargets",
#      "elasticloadbalancing:DescribeListenerCertificates",
#      "elasticloadbalancing:DescribeListeners",
#      "elasticloadbalancing:DescribeLoadBalancers",
#      "elasticloadbalancing:DescribeLoadBalancerAttributes",
#      "elasticloadbalancing:DescribeRules",
#      "elasticloadbalancing:DescribeSSLPolicies",
#      "elasticloadbalancing:DescribeTags",
#      "elasticloadbalancing:DescribeTargetGroups",
#      "elasticloadbalancing:DescribeTargetGroupAttributes",
#      "elasticloadbalancing:DescribeTargetHealth",
#      "elasticloadbalancing:ModifyListener",
#      "elasticloadbalancing:ModifyLoadBalancerAttributes",
#      "elasticloadbalancing:ModifyRule",
#      "elasticloadbalancing:ModifyTargetGroup",
#      "elasticloadbalancing:ModifyTargetGroupAttributes",
#      "elasticloadbalancing:RegisterTargets",
#      "elasticloadbalancing:RemoveListenerCertificates",
#      "elasticloadbalancing:RemoveTags",
#      "elasticloadbalancing:SetIpAddressType",
#      "elasticloadbalancing:SetSecurityGroups",
#      "elasticloadbalancing:SetSubnets",
#      "elasticloadbalancing:SetWebACL",
#    ]
#
#    resources = ["*"]
#  }
#
#  statement {
#    actions = [
#      "iam:CreateServiceLinkedRole",
#      "iam:GetServerCertificate",
#      "iam:ListServerCertificates",
#    ]
#
#    resources = ["*"]
#  }
#
#  statement {
#    actions = [
#      "cognito-idp:DescribeUserPoolClient",
#    ]
#
#    resources = ["*"]
#  }
#
#  statement {
#    actions = [
#      "tag:GetResources",
#      "tag:TagResources",
#    ]
#
#    resources = ["*"]
#  }
#
#  statement {
#    actions = [
#      "waf:GetWebACL",
#      "waf-regional:GetWebACLForResource",
#      "waf-regional:GetWebACL",
#      "waf-regional:AssociateWebACL",
#      "waf-regional:DisassociateWebACL",
#    ]
#
#    resources = ["*"]
#  }
#
#  statement {
#    actions = [
#      "shield:DescribeProtection",
#      "shield:GetSubscriptionState",
#      "shield:DeleteProtection",
#      "shield:CreateProtection",
#      "shield:DescribeSubscription",
#      "shield:ListProtections"
#    ]
#    resources = ["*"]
#  }
#}
#
#resource "aws_iam_policy" "this" {
#  name        = "${var.aws_resource_name_prefix}${var.k8s_cluster_name}-alb-management"
#  description = "Permissions that are required to manage AWS Application Load Balancers."
#  path        = local.aws_iam_path_prefix
#  policy      = data.aws_iam_policy_document.alb_management.json
#}
#
#resource "aws_iam_role_policy_attachment" "this" {
#  policy_arn = aws_iam_policy.this.arn
#  role       = aws_iam_role.this.name
#}

resource "kubernetes_service_account" "this" {
  automount_service_account_token = true
  metadata {
    name      = "alb-ingress-controller"
    namespace = var.k8s_namespace
    #    annotations = {
    #      # This annotation is only used when running on EKS which can
    #      # use IAM roles for service accounts.
    #      "eks.amazonaws.com/role-arn" = aws_iam_role.this.arn
    #    }
    labels = {
      "app.kubernetes.io/name"       = "alb-ingress-controller"
      "app.kubernetes.io/managed-by" = "terraform"
    }
  }
}

resource "kubernetes_cluster_role" "this" {
  metadata {
    name = "alb-ingress-controller"

    labels = {
      "app.kubernetes.io/name"       = "alb-ingress-controller"
      "app.kubernetes.io/managed-by" = "terraform"
    }
  }

  rule {
    api_groups = [
      "",
      "extensions",
    ]

    resources = [
      "configmaps",
      "endpoints",
      "events",
      "ingresses",
      "ingresses/status",
      "services",
      "pods/status",
    ]

    verbs = [
      "create",
      "get",
      "list",
      "update",
      "watch",
      "patch",
    ]
  }

  rule {
    api_groups = [
      "",
      "extensions",
    ]

    resources = [
      "nodes",
      "pods",
      "secrets",
      "services",
      "namespaces",
    ]

    verbs = [
      "get",
      "list",
      "watch",
    ]
  }
}

resource "kubernetes_cluster_role_binding" "this" {
  metadata {
    name = "alb-ingress-controller"

    labels = {
      "app.kubernetes.io/name"       = "alb-ingress-controller"
      "app.kubernetes.io/managed-by" = "terraform"
    }
  }

  role_ref {
    api_group = "rbac.authorization.k8s.io"
    kind      = "ClusterRole"
    name      = kubernetes_cluster_role.this.metadata[0].name
  }

  subject {
    kind      = "ServiceAccount"
    name      = kubernetes_service_account.this.metadata[0].name
    namespace = kubernetes_service_account.this.metadata[0].namespace
  }
}

resource "kubernetes_deployment" "this" {
  depends_on = [kubernetes_cluster_role_binding.this]

  metadata {
    name      = "alb-ingress-controller"
    namespace = var.k8s_namespace

    labels = {
      "app.kubernetes.io/name"       = "alb-ingress-controller"
      "app.kubernetes.io/version"    = "v${local.aws_alb_ingress_controller_version}"
      "app.kubernetes.io/managed-by" = "terraform"
    }

    annotations = {
      "field.cattle.io/description" = "AWS ALB Ingress Controller"
    }
  }

  spec {

    replicas = var.k8s_replicas

    selector {
      match_labels = {
        "app.kubernetes.io/name" = "alb-ingress-controller"
      }
    }

    strategy {
      type = "Recreate"
    }

    template {
      metadata {
        labels = merge(
          {
            "app.kubernetes.io/name"    = "alb-ingress-controller"
            "app.kubernetes.io/version" = local.aws_alb_ingress_controller_version
          },
          var.k8s_pod_labels
        )
        #        annotations = merge(
        #          {
        #            # Annotation which is only used by KIAM and kube2iam.
        #            # Should be ignored by your cluster if using IAM roles for service accounts, e.g.
        #            # when running on EKS.
        #            "iam.amazonaws.com/role" = aws_iam_role.this.arn
        #          },
        #          var.k8s_pod_annotations
        #        )
      }

      spec {
        affinity {
          pod_anti_affinity {
            preferred_during_scheduling_ignored_during_execution {
              weight = 100
              pod_affinity_term {
                label_selector {
                  match_expressions {
                    key      = "app.kubernetes.io/name"
                    operator = "In"
                    values   = ["alb-ingress-controller"]
                  }
                }
                topology_key = "kubernetes.io/hostname"
              }
            }
          }
        }

        automount_service_account_token = true

        dns_policy = "ClusterFirst"

        restart_policy = "Always"

        container {
          name                     = "server"
          image                    = local.aws_alb_ingress_controller_docker_image
          image_pull_policy        = "Always"
          termination_message_path = "/dev/termination-log"

          env {
            name  = "AWS_ACCESS_KEY_ID"
            value = var.aws_assess_key_id
          }
          env {
            name  = "AWS_SECRET_ACCESS_KEY"
            value = var.aws_secret_access_key
          }

          args = [
            "--ingress-class=${local.aws_alb_ingress_class}",
            "--cluster-name=${var.k8s_cluster_name}",
            "--aws-vpc-id=${local.aws_vpc_id}",
            "--aws-region=${local.aws_region_name}",
            "--aws-max-retries=10",
          ]

          port {
            name           = "health"
            container_port = 10254
            protocol       = "TCP"
          }

          readiness_probe {
            http_get {
              path   = "/healthz"
              port   = "health"
              scheme = "HTTP"
            }

            initial_delay_seconds = 30
            period_seconds        = 60
            timeout_seconds       = 3
          }

          liveness_probe {
            http_get {
              path   = "/healthz"
              port   = "health"
              scheme = "HTTP"
            }

            initial_delay_seconds = 60
            period_seconds        = 60
          }
        }

        service_account_name             = kubernetes_service_account.this.metadata[0].name
        termination_grace_period_seconds = 60
      }
    }
  }
}
